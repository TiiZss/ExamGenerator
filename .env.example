# ExamGenerator - Environment Variables Example
# Copia este archivo a .env y configura tus valores

# ============================================
# API Keys
# ============================================

# Google Gemini API Key (para generaci贸n de preguntas con IA)
GOOGLE_API_KEY=tu-api-key-aqui

# ============================================
# Configuraci贸n Web
# ============================================

# Puerto para la interfaz web (default: 5000)
EXAMGEN_WEB_PORT=5000

# Entorno Flask: development o production
FLASK_ENV=production

# ============================================
# Configuraci贸n IA
# ============================================

# Modelo de Gemini a usar (default: gemini-1.5-flash)
# Opciones: gemini-1.5-flash, gemini-1.5-pro
GEMINI_MODEL=gemini-1.5-flash

# Modelo de Ollama a usar (default: llama2)
# Modelo de Ollama por defecto
# Recomendados CPU: phi3:mini (2.2GB), llama3.2:1b (1.3GB), gemma2:2b (1.6GB)
# Recomendados GPU: phi3:medium (7.9GB), llama3:8b (4.7GB)
OLLAMA_MODEL=phi3:mini

# URL de Ollama
# Docker (red interna): http://ollama:11434
# Docker (Windows/Mac host): http://host.docker.internal:11434
# Local: http://localhost:11434
OLLAMA_URL=http://ollama:11434

# Puerto de Ollama (default: 11434)
OLLAMA_PORT=11434

# ============================================
# Configuraci贸n Docker
# ============================================

# Prefijo para logs
LOG_LEVEL=INFO

# Timezone
TZ=Europe/Madrid
